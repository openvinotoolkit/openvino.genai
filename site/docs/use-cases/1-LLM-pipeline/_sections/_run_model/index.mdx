import CodeExamplePython from './_code_example_python.mdx';
import CodeExampleCPP from './_code_example_cpp.mdx';

## Run Model Using OpenVINOâ„¢ GenAI

`LLMPipeline` is the main object used for decoding. You can construct it straight away from the folder with the converted model.
It will automatically load the main model, tokenizer, detokenizer and default generation configuration.

<LanguageTabs>
    <TabItemPython>
        <Tabs groupId="device">
            <TabItem label="CPU" value="cpu">
                <CodeExamplePython device="CPU" />
            </TabItem>
            <TabItem label="GPU" value="gpu">
                <CodeExamplePython device="GPU" />
            </TabItem>
        </Tabs>
    </TabItemPython>
    <TabItemCpp>
        <Tabs groupId="device">
            <TabItem label="CPU" value="cpu">
                <CodeExampleCPP device="CPU" />
            </TabItem>
            <TabItem label="GPU" value="gpu">
                <CodeExampleCPP device="GPU" />
            </TabItem>
        </Tabs>
    </TabItemCpp>
</LanguageTabs>

:::note

Use CPU or GPU as devices without any other code change.

:::
