--extra-index-url https://download.pytorch.org/whl/cpu
diffusers==0.34.0
optimum-intel @ git+https://github.com/huggingface/optimum-intel.git@main
numpy<2.0.0; platform_system == "Darwin" and platform_machine == "x86_64"
onnx==1.18.0
pytest
pytest-html
hf_transfer
langchain_community
gguf>=0.10.0


# requirements for awq and gptq models.
# install gptqmodel from the GitHub repository to awoid issues with the cuda kernels building
gptqmodel @ git+https://github.com/alexsu52/GPTQModel.git#egg=gptqmodel

# requirements for specific models
# - hf-tiny-model-private/tiny-random-RoFormerForCausalLM
rjieba
# - baichuan-inc/Baichuan2-7B-Chat
bitsandbytes
# - nomic-ai/gpt4all-falcon
# - Qwen/Qwen-7B
# - Qwen/Qwen-7B-Chat
# - mosaicml/mpt-7b
# - internlm/internlm2-7b
einops
# - Qwen/Qwen-7B
# - Qwen/Qwen-7B-Chat
transformers_stream_generator
# - openbmb/MiniCPM-V-2
torchvision
# - openbmb/MiniCPM-V-2
timm
# - Qwen/Qwen-7B
# - Qwen/Qwen-7B-Chat
# - Salesforce/xgen-7b-8k-base
tiktoken
# - microsoft/biogpt
sacremoses
# - openai/whisper-base
librosa
soundfile
datasets
rouge
# - microsoft/Phi-4-multimodal-instruct
peft
